Slides: <https://static.frontendmasters.com/resources/2024-04-09-ux-testing/user-research-testing.pdf>

> This is not best practice, but rather a way to get started and build upon.

> What can pragmatically be done wih no time and no budget.

> Do what you can. Something is better than nothing.

## Principles

Benefits (for you)

- Be proved right (justify to stakeholders)
- Deal w/ bad ideas (avoid confrontation; suggest testing)
- Avoid criticism later 

Benefits (for organization)

- Risk management
- Market fit
- Speed to market (GTM)

Appealing to stakeholders

- Finance: reduce failure / going over budget
- Sales & Marketing: increase change of success
- Devs: streamline dev & reduce wasted effort

Proving (the) value

- Start small & grow
- Involve stakeholders (invite to watch & share out)
- Communicate successes (try to associate $$$)

Dealing with resistance

- People resist change
- Cannot get access to audience
  - Use existing assets (data, comments, feedback, anecdotes, etc)
  - Use surrogates (engage with similar to target audience)
  - Work w/ colleagues (customer facing staff)

"You haven't spoken to enough people"

Biased results

- Minimize bias (parse questions; could leverage LLMs)
- Be aware (of the limitations)
- Go more in-depth

"It will be disruptive and take too long"

- Just do it (don't give people the opportunity to say no)
- Don't ask (for time, money, etc)
- No extra time (prevent impact of project timeline)

Use every tiny moment

- Use tests that take < 1hr
  - First-click, 5-second test, eye-tracking
- Focus on (fast) results
  - <https://www.pollfish.com/>
- Use natural breaks in projects (waiting for feedback; delivery of content)

Manufacturing excuses

- Preparing to present (excuse to do research)
- Answering questions (excuse to do research)
- Exploring options (research to break a tie)

> **Hide the cost:** don't include as a line-item unless the org is user-
> centric. It will always be the first thing cut.

> _Doing something is better than doing nothing._

When to do research and/or testing?

- Don't doing it for the sake of it, be specific (unanswered questions)
- Resolve disagreements
  - "Does it work?"
  - "Which is better?"
  - "Will users like it?"
- Inappropriate information (not relevant/right)
  - Out of date data or personas
  - Biased
  - Unfit for purpose (personas by marketing that don't work for UX)

> _Test early, test often._

_Don't Make Me Think_ and the sequel _Rocket Surgery Made Easy_.

Test early
- Cheaper to fix
- Faster to market
- Easier to adjust

When testing usability
- Little point testing w/ more than (6) people
- (3) people catch 75% of problems
- Test with anybody w/ comparable ability

<https://www.askable.com/>

Internal testers? Bullshit. Too close to the product / org / sector / problem space.
- Friends & family preferable.
- If use employees, favor ones who work closer w/ users

MS Clarity is a free tool.

Free plans
- Lyssna: quick tests
- Maze: all-around
- UX Metrics: cart sorting & tree testing
- Lookback: facilitated usability testing

In conclusion:
- Doesn't have to be expensive in terms of money & time
- Don't wait (for permission) just start
- Can achieve a lot without much budget or time

## Upfront Research & Testing

Why not skip upfront research?
- Confusion (assumptions & misunderstandings cause chaos later)
- Disagreement leads to iteration hell
- No context

The minimum you need to know
- Who is the audience?
- What are their needs?
- What is their overall experience?
- Where do they encounter friction?

Keep it light(weight)
- Consolidate (often existing research or info out there)

Segment audience based on questions, tasks, and needs

> **Warning:** be careful with demographics. Use cases >>> demographics.

Don't worry about "doing it wrong" because the participants won't know. :)

"Empathy map" is essentially a persona but UX focused instead of marketing.

Journey mapping workshop (~3 hours e.g. half-day)
- Alternative to a kick-off or scope defining meeting (something early that's already scheduled)
- Invite (most to least value left to right)
  - End users, Customer facing staff, Peeps w/ data, Executive sponsor (most senior person you can find)
- Deciding on scope
  - 5 steps, focus broadly or more micro

|             | discover | research | purchase | delivery | post-sales |
|-------------|----------|----------|----------|----------|------------|
| task        |          |          |          |          |            |
| questions   |          |          |          |          |            |
| touchpoints |          |          |          |          |            |
| emotions    |          |          |          |          |            |
| influences  |          |          |          |          |            |
| weaknesses  |          |          |          |          |            |

Why upfront test?
- Check assumptions
- Low cost (no need to build anything)
- SWOT (strength, weakness, opportunity, threat)

Monitoring
- Analytics: where are they abandoning?
- Heat maps: where there is friction (heh, heat map)
- Session recording: visualize it

In conclusion:
- Keep lean & hide cost
- Take time to identify audience (+ understand needs)
- Consider mapping the journey & testing

## Planning Information Architecture

Main tool referenced: UXMetrics

Top tasks: identify the 20% of content/features that 80% of users will be interested in.

Focus on top-level nav.

Card sorting: users organize things in a way that makes sense to them.

Open: users create their own groupings vs Closed: pre-defined groups.

IA tips:
- Fewer options better: can only hold (4) items in short-term memory
- Group options
- Keep labels short
- Avoid ambiguity
- Be distinct
- Don't fear clicks

Tree testing: check assumptions on things with low agreement or "not sure" group.

## Testing: Design Concepts

Main tool referenced: Lyssna

Do they like it? Do they get it? Can they use it?

Divide aesthetics & usability for testing.

Testing comprehension: do users understand what the page is about and what actions they can take.

5-second test really becomes an 8-second test.

Brand Deck: <https://branding.cards/>

Semantic differential survey: does the design match the brand keywords looking to be communicated?

<https://en.wikipedia.org/wiki/Semantic_differential>

Eye tracking (RealEye) can be done via webcam these days.

"Spell checker for designers" is eye-tracking simulation based on AI that outputs heatmaps.

<https://attentioninsight.com/>

Hemingway is an app for taking existing copy to make it more better. <https://hemingwayapp.com/>

## Testing: Prototypes

Tool referenced: Lookback

Why? Closer to actual UX and is interactive.

## Testing: Existing Sites/Apps

"The best testing is once you've gone live"

Why post-launch testing & iteration?
- Natural behavior at scale
- Deliver results

"We all hate GA4"

Exit rate == last in the session
Bounce rate == only in the session

A/B testing for smaller changes e.g. image, color of button, text, etc.

A/B == single change at a time

Multivariate == multiple changes

Convert is good but expensive. Crazyegg is much cheaper.

Once again, _something is better than nothing_.
